<!DOCTYPE html>

<html lang="en">
<head>
    <meta charset="utf-8">
    <meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible">
    <meta content="width=device-width, initial-scale=1.0" name="viewport">
    <meta content="" name="description">
    <meta content="" name="author">

    <title>Seongkook Heo</title>
    <link crossorigin="anonymous" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css"
    integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" rel="stylesheet">
    <link href="style.css" rel="stylesheet" type="text/css"><!-- Optional theme -->
    <link crossorigin="anonymous" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap-theme.min.css"
    integrity="sha384-fLW2N01lMqjakBkx3l/M9EahuwpSfeNvV63J5ezn3uZzapT0u7EYsXMjQV+0En5r" rel="stylesheet">
    <!-- Latest compiled and minified JavaScript -->

    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js">
    </script>
</head>

<body data-spy="scroll" data-target=".navbar-fixed-top" id="page-top">
    <nav class="navbar navbar-default navbar-fixed-top" role="navigation">
        <div class="container">
            <div class="navbar-header page-scroll">
                <button class="navbar-toggle" data-target=".navbar-ex1-collapse" data-toggle="collapse" type=
                "button"><span class="sr-only">Toggle navigation</span> <span class="icon-bar"></span> <span class=
                "icon-bar"></span> <span class="icon-bar"></span></button> <a class="navbar-brand page-scroll" href=
                "#page-top"><strong>Seongkook Heo</strong></a>
            </div>
            <!-- Collect the nav links, forms, and other content for toggling -->


            <div class="collapse navbar-collapse navbar-ex1-collapse navbar-right">
                <ul class="nav navbar-nav">
                    <!-- Hidden li included to remove active class from about link when scrolled up past about section -->


                    <li class="hidden">
                        <a class="page-scroll" href="#page-top"></a>
                    </li>


                    <li>
                        <a class="page-scroll" href="#page-top">About</a>
                    </li>


                    <li>
                        <a class="page-scroll" href="#research">Research</a>
                    </li>


                    <li>
                        <a class="page-scroll" href="#publication">Publication</a>
                    </li>


                    <li>
                        <a class="page-scroll" href="#fun">Fun</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>


    <section class="intro-section" id="about">
        <div class="container"><img class="img-responsive" src="me.jpg">
        </div>


        <div class="container">
            <h1 id="seongkookheo">Seongkook Heo</h1>


            <p>Hi. I&#8217;m Seongkook Heo, a PhD candidate at the <a href="http://kaist.ac.kr">KAIST</a>. I&#8217;m
            studying HCI, especially things related to developing new way to interact with computers in different-form
            factors, with my advisor <a href="http://hcil.kaist.ac.kr/">Geehyuk Lee</a>. I was lucky to have chances to
            collaborate with different companies, such as Samsung Electronics, Hyundai Motors, Golfzon, and Hancom, and
            with researchers in different departments, from electronic engineering to industrial design. Last summer, I
            was an intern at Microsoft Research with Ken Hinckley, which was also a great experience. I learned a lot
            from these experiences. I'm currently at Autodesk Research in Toronto for my internship with Tovi
            Grossman.</p>


            <p>I always have been a geek and it is exciting to see the technologies that I&#8217;ve seen in books and
            movies are becoming real. Now computers are everywhere, and even very small computers like the ones on our
            wrist are strong enough to run various apps and connected to the internet. However, I think computers are
            still not paying enough attention to us, like what we wanted to do, what we can do, or what we really meant
            to do, so that we have to put much effort to let them work for us. I am enthusiastic about making these
            &#8216;rude&#8217; computers to become more sensitive to us, so that we can benefit the mighty power of
            computers better.</p>


            <p>What I love: thinking and building new idea, solving problems, things that are beautiful, either
            aesthetically, logically, or mecahnically, or something with a brilliant idea. And a bike. </p>


            <p><a href="mailto:seongkook@kaist.ac.kr"><strong>Email</strong></a> | <a href=
            "cv.pdf"><strong>CV</strong></a> | <a href=
            "https://scholar.google.com/citations?hl=en&amp;user=7r0_F0kAAAAJ"><strong>Google scholar</strong></a></p>
        </div>
        <!--p.s: I'm on a job market. Please ping me if you're interested.-->
    </section>


    <section class="content-section" id="research">
        <div class="container">
            <h2 id="research">Research</h2>


            <p>Our natural touch is rich and nuanced with full of physical properties such as force and posture
            implying our intentions. Touch interfaces, however, ignore this rich information and only consider whether
            our finger is in contact within a screen area and the contact location. In this talk, I will present
            different approaches my colleagues and I made to enhance impoverished touch interaction, for instance by
            using additional modalities like force or hover, or by exploiting underutilized touch gestures.</p>


            <h3 id="force-enrichedtouch">Force-enriched touch</h3>


            <p class="project-content">When we touch a surface, the touch makes the surface to move, differently by the
            speed of the finger lands on the surface. <b>ForceTap</b> tried to detect this movement with an
            accelerometer embedded on a mobile phone and use this to make a <i>tap</i> to a <i>strong tap</i> and a
            <i>gentle tap</i>. While we're touching the surface, we can control the force, in <i>a normal and
            tangential directions</i>. This is what we are used to do; we interact with physical objects with force,
            sometimes make a dent on it and sometimes we examine its physical property. What if we can utilize these
            force on a touch screen? That's how our <b>Force Gestures</b> came out. We built a device that can sense
            both <i>normal and tangential force</i> with touch and explored the use of these rich input. Force is a
            continuous property, so it has its richness by itself even only with a single-dimensional force: normal
            force. In <b>ForceDrag</b>, with our force-senitive touch prototype, we showed two way of utilizing
            <i>normal force</i> to work well with a touch screen: apply force to decide touch mode and drag without
            force and simultaneously control force and touch to support continuous mode change. Tangential force has
            richer information than normal force with its directional information. However, tangential force is
            difficult to be measured at multiple locations on a touch surface since previous methods measure the
            tangential force transferred through the surface. We thus developed a new method to <b>estimate tangential
            force from the slight touch movement</b> made from the <i>finger deformation</i>, a result of the
            combination of tangential force, friction, and elastic nature of our finger.</p>


            <h4 class="project-title">ForceTap</h4>


            <p class="project-content">SeongKook Heo and Geehyuk Lee, <strong>ForceTap: Extending Input Vocabulary of
            Mobile Touch Screen by Adding Tap Gestures</strong>, MobileHCI 2011 <a href=
            "http://dl.acm.org/citation.cfm?id=2037373.2037393">Paper</a> / <a href=
            "https://www.youtube.com/watch?v=J-XXuRzaYrQ">Video</a></p>


            <p class="project-content">Force is a great modality that can enrich touch with continuous pressure level.
            But as of 2011, there were almost no device with force-sensing capability except the BlackBerry Storm 2,
            which was unfortunately not very successful. It is understandable since adding force sensors would result
            in the increased manufacturing price and more complex structure. We came with a new idea of using an
            accelerometer, which almost all modern mobile devices have, to detect a strong and gentle tap by measuring
            the device movement made by a tap.</p>


            <h4 class="project-title">Force Gestures</h4>


            <p class="project-content">SeongKook Heo and Geehyuk Lee, <strong>Force Gestures: Augmenting Touch Screen
            Gestures with Normal and Tangential Forces</strong>, UIST 2011 <a href=
            "http://dl.acm.org/citation.cfm?id=2047278">Paper</a> / <a href=
            "https://www.youtube.com/watch?v=RZlq4TOjHi0">Video</a></p>


            <p class="project-content">When we touch a real world object, physics counts. We automatically control
            force in multiple directions. It creates tremendous different manipulations and expresses different nuance.
            What if a touch screen can utilize multi-dimensional force with touch operation? In this project, we
            developed a normal- and tangential-force sensing mobile touch device and showed the potential of combining
            touch with force with application scenarios.</p>


            <h4 class="project-title">ForceDrag</h4>


            <p class="project-content">SeongKook Heo and Geehyuk Lee, <strong>ForceDrag: Using Pressure as a Touch
            Input Modifier</strong>, OZCHI 2012 <a href="http://dl.acm.org/citation.cfm?id=2414572">Paper</a> /
            <a href="https://www.youtube.com/watch?v=u096tD1CJUo">Video</a></p>


            <p class="project-content">We thought about using force for touch input modifier, like using modifier keys
            to make a mouse drag work for a different function. During the process, we found that the friction makes
            the forceful movement difficult to make (which is too obvious). So we proposed a new way, named
            &#8216;force lock&#8217; to support light drag after selecting a mode with a different force level. We also
            discussed pros and cons of using force lock compared to just using force as a modifier.</p>


            <h4 class="project-title">Multi-touch Shear Interaction</h4>


            <p class="project-content">SeongKook Heo and Geehyuk Lee, <strong>Indirect Shear Force Estimation for
            Multi-Point Shear Force Operations</strong>, CHI 2013 <a href=
            "http://dl.acm.org/citation.cfm?id=2470693">Paper</a> / <a href=
            "https://www.youtube.com/watch?v=1B9BmsHLCEM">Video</a></p>


            <p class="project-content">Use of a tangential force has been introduced in 2011 as noted above. But think
            about how we interact with objects and also touch surfaces. We use multiple fingers.</p>


            <h3 id="hover-enrichedtouch">Hover-enriched touch</h3>


            <p class="project-content">I used the term <i>hover</i> here, but it's actually on what's happening on and
            right above the touch surface. This is important and takes a very important role in the real world. Where
            our finger came from, how its posture is like, or how fast it's movement all matters how it is used. We
            built a hover-tracking touchpad, <strong>ThickPad</strong>, using infrared LEDs and Photo transistors and
            putting a transparent and touch-sensitive conductive sheet on it. Thus, it can track finger position over
            the surface and shape of fingers. After we tested its successful sensing capability, we built a larger
            hover-tracking optical touchpad, which we named as <strong>LongPad</strong>, that can cover whole laptop
            palmrest area. The area and shape-detection capability allowed us to block &gt;99% of accidental touches
            made by the palm contact and to have rich interaction such as bimanual touch interactions. We further
            explored the possibilities of using both hover and force information with various scenarios.
            <strong>Pre-Touch</strong> explores the hover input space in a more sophisticated and holistic way, but
            I'll describe about this later (after the publication).</p>


            <h4 class="project-title">ThickPad</h4>


            <p class="project-content">Sangwon Choi, Jaehyun Han, Sunjun Kim, Seongkook Heo, Geehyuk Lee,
            <strong>ThickPad: A Hover-Tracking Touchpad for a Laptop</strong>, UIST 2011 Demo
                         <a href="http://dl.acm.org/citation.cfm?id=2046405">Paper</a></p>


            <h4 class="project-title">LongPad</h4>


            <p class="project-content">Jiseong Gu, SeongKook Heo, Jaehyun Han, Sunjun Kim, and Geehyuk Lee,
            <strong>LongPad: A TouchPad Using the Whole Area below the Keyboard on a Laptop</strong>, CHI 2013
            <a href="http://dl.acm.org/citation.cfm?id=2466188">Paper</a> | <a href="https://www.youtube.com/watch?v=9zNOSGkWDfg">Video</a></p>


            <h4 class="project-title">2.5D interaction</h4>


            <p class="project-content">Seongkook Heo, Jaehyun Han, Geehyuk Lee, <strong>Designing Rich Touch
            Interaction through Proximity and 2.5D Force Sensing Touchpad</strong> OZCHI 2013
            <a href="http://dl.acm.org/citation.cfm?id=2541057">Paper</a>
            </p>


            <p class="project-content">Seongkook Heo, Jaehyun Han, and Geehyuk Lee, <strong>Designing for Hover- and
            Force-Enriched Touch Interaction</strong>, Computer-Human Interaction. Cognitive Effects of Spatial
            Interaction, Learning, and Ability Lecture Notes in Computer Science Volume 8433
            <a href="http://link.springer.com/chapter/10.1007%2F978-3-319-16940-8_4">Paper</a></p>


            <h4 class="project-title">PreTouch</h4>


            <p class="project-content">Ken Hinckley, Seongkook Heo, Michel Pahud, Christian Holz, Hrvoje Benko, Abigail
            Sellen, Richard Banks, Kenton O’Hara, Gavin Smyth, and William Buxton, <strong>Pre-Touch Sensing for Mobile
            Interaction</strong>, CHI2016 (to appear)</p>


            <p class="project-content">This work is from my internship with Ken Hinckley at MSR during 2015 summer.
            Details to be described later.</p>


            <h3 id="gettingthemostoutoftouch">Getting the most out of touch</h3>
            <p class="project-content">
            Other than physical properties made while we are touching the surface, we also have a great control of making quick and accurate finger movements. We explored what our fingers can do better. However, sometimes, these are not enabled on touch input. <b>Consecutive distant taps</b> are fairly easy to perform with our fingers, but has not been used on touch input. We designed ways to utilize this new input for richer input vocabulary on mobile touch interface. 
            
            How about the precision of our fingers? It's known as a pretty inaccurate input, but in fact, people can even type on a tiny smartwatch. We developed <b>SplitBoard</b>, which splits the QWERTY keyboard in half of its size and use a flick gesture, which is not well utilzed for text entry (especially on small screens that make the drawing movement on a keyboard difficult), to switch between different part of the keyboard. 

            </p>


            <h4 class="project-title">Consecutive Distant Taps</h4>

            <p class="project-content">SeongKook Heo, Jiseong Gu, and Geehyuk Lee, <strong>Expanding Touch Input Vocabulary by Using Consecutive Distant Taps</strong>, CHI 2014 <a href="http://dl.acm.org/citation.cfm?id=2557234">Paper</a> | <a href="https://www.youtube.com/watch?v=Qydq5l2utKA">Video</a></p>

            <p class="project-content">Tapping on the same point twice is a common operation known as double tap, but
            tapping on distant points in sequence is underutilized. We explore the potential uses of consecutive
            distant tap operations.</p>



            <h4 class="project-title">SplitBoard</h4>


            <p class="project-content">Jonggi Hong, Seongkook Heo, Poika Isokoski, and Geehyuk Lee, <strong>SplitBoard: A Simple Split Soft Keyboard for Wristwatch-sized Touch Screens</strong>,CHI 2015
            <a href="http://dl.acm.org/citation.cfm?id=2702273">Paper</a> | <a href="https://www.youtube.com/watch?v=VE42fxNJZrk">Video</a></p>


            <p class="project-content">SplitBoard is a new soft keyboard designed for a smartwatch. As the user flicks
            left or right on the keyboard, it switches between the left and right halves of a QWERTY keyboard. The
            SplitBoard is expected to be a viable option for smartwatch text entry because of its light processing
            requirements, good performance, and immediate learnability.</p>


            <h3 id="sensing6dof">Sensing 6DOF</h3>
            <p class="project-content">6DOF, which describes a combination of both 3D position and 3D posture information, sensing devices have been used since very early days of computing history. With 6DOF sensing, we can understand where an object is located and how it is tilted. However, 6DOF sensing devices are expensive and require large tracking object. Through a collaborative project with Samsung Electronics, we built a new method to measure 6DOF of a tracker using only cheap and off-the-shelf parts: infrared LEDs and photodiodes. Our projects, <b>IrCube</b> and <b>IrPen</b> describes how this method works and how we can utilize this for various use scenarios. </p>

            <h4 class="project-title">IrCube</h4>
            <p class="project-content">Seongkook Heo, Jaehyun Han, Sangwon Choi, Seunghwan Lee, Geehyuk Lee, Hyong-Euk Lee, SangHyun Kim, Won-Chul Bang, DoKyoon Kim, and ChangYeong Kim, <strong>IrCube Tracker: An Optical 6-DOF Tracker based on LED Directivity</strong>, UIST '11 <a href="http://dl.acm.org/citation.cfm?id=2047272">Paper</a> | <a href="https://www.youtube.com/watch?v=-se-cPXvPVY">Video</a></p>
            <p class="project-content">Jaehyun Han, Seongkook Heo, Geehyuk Lee, Won-Chul Bang, DoKyoon Kim, and ChangYeong Kim,
            <strong>6-DOF tracker using LED directivity</strong>, Electronics Letters, 47(3):177-178, 2011 <a href="http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=5710053">Paper</a>


            <p class="project-content">We designed an optical 6-DOF tracker where a few photo-sensors can track the
            position and orientation of an LED cluster. The operating principle of the tracker is basically source
            localization by solving an inverse problem. We further implemented a smaller version of IrCube sensors and
            explored the use of 6-DOF stylus on touch tablets.</p>

            <h4 class="project-title">IrPen</h4>
            <p class="project-content">Jaehyun Han, Seongkook Heo, Hyong-Euk Lee, and Geehyuk Lee, <strong>
IrPen: A 6-DOF Pen System to Support Over-the-surface Interactions with Tablet Computers,</strong>
IEEE Computer Graphics and Applications, 34(3)
 <a href="http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=6813983">Paper</a> | <a href=
            "https://www.youtube.com/watch?v=AvhKnDu4rLg">Video</a></p>


            <p class="project-content">Researchers have proposed various techniques for over-the-surface interaction
            using pens. However, current pen systems can't properly support these techniques because of their limited
            tracking abilities. The IrPen, an extension of the IrCube tracker, is a six-degree-of-freedom pen system
            that properly supports over-the-surface interaction on tablet computers. Besides incorporating the
            tracker's basic operating principles, the IrPen takes into account tablet-specific requirements. It employs
            a sensor small enough for tablets, and the pen structure minimizes issues caused by reflections from a
            tablet surface. The design also addresses issues related to occlusion and ambient lighting.</p>




            <h3 id="others">Understanding people</h3>


            <h4 class="project-title">Snapping</h4>


            <p class="project-content">Results from previous research, we assumed using the centroid, rather than the
            bounding box center, would provide a better way to help users with aligning objects. Through a user study,
            we examined the position of a center perceived by a user when aligning objects.</p>


            <p class="project-content">Presented at CHI '12 (WIP) <a href="paper%20link">Paper</a></p>


            <h4 class="project-title">Mining social relationship</h4>


            <p class="project-content">Our goal is to show that it is possible to automatically infer social
            relationship types among people who stay together in an organization by analyzing communication patterns.
            We collected indoor co-location data and instant messenger data from 22 participants for one month. Based
            on the data, we designed and explored several indicators which are considered to be useful for mining
            social relationship types. We applied machine learning techniques using the indicators and found that it is
            possible to develop an intelligent method to infer social relationship types.</p>


            <p class="project-content">Presented at CSCW '13 <a href="paper%20link">Paper</a></p>


            <h4 class="project-title">Participatory design</h4>


            <p class="project-content">We proposed a novel design method called Formula One, which supports quick and
            easy development of interactive prototype by using the video call functionalities of consumer smart mobile
            appliances. The Formula One method consists of two-stages, which are Pit Stop and Drive that a user and
            designers design and modify a prototype and test it, respectively.</p>


            <p class="project-content">Presented at HCI Korea 2016 (Received best paper award) <a href=
            "paper%20link">Paper</a> | <a href="paper%20link">Video</a></p>
        </div>
    </section>


    <section class="content2-section" id="publication">
        <div class="container">
            <h2 id="publications">Publications</h2>


            <h3 id="peer-reviewedconerencepapersandnotes">Peer-reviewed Conerence Papers and Notes</h3>


            <ul>
                <li>Ken Hinckley, Seongkook Heo, Michel Pahud, Christian Holz, Hrvoje Benko, Abigail Sellen, Richard
                Banks, Kenton O’Hara, Gavin Smyth, and William Buxton<br>
                <strong>Pre-Touch Sensing for Mobile Interaction</strong><br>
                CHI2016 (to appear)</li>


                <li>Jonggi Hong, Seongkook Heo, Poika Isokoski, and Geehyuk Lee<br>
                <strong>SplitBoard: A Simple Split Soft Keyboard for Wristwatch-sized Touch Screens</strong><br>
                CHI 2015</li>


                <li>Seongkook Heo, Jiseong Gu, Geehyuk Lee<br>
                <strong>Expanding Touch Input Vocabulary by Using Consecutive Distant Taps</strong><br>
                CHI 2014</li>


                <li>Seongkook Heo, Jaehyun Han, Geehyuk Lee,<br>
                <strong>Designing Rich Touch Interaction through Proximity and 2.5D Force Sensing Touchpad</strong><br>
                OZCHI 2013</li>


                <li>Seongkook Heo, Geehyuk Lee<br>
                <strong>Indirect Shear Force Estimation for Multi-Point Shear Force Operations</strong><br>
                CHI 2013</li>


                <li>Jiseong Gu, SeongKook Heo, Jaehyun Han, Sunjun Kim, Geehyuk Lee<br>
                <strong>LongPad: A TouchPad Using the Entire Area below the Keyboard of a Laptop Computer</strong><br>
                CHI 2013</li>


                <li>Jinhyuk Choi, SeongKook Heo, Jaehyun Han, Geehyuk Lee, and Junehwa Song<br>
                <strong>Mining Social Relationship Types in an Organization using Communication Patterns</strong><br>
                CSCW 2013</li>


                <li>SeongKook Heo and Geehyuk Lee<br>
                <strong>ForceDrag: Using Pressure as a Touch Input Modifer</strong><br>
                OZCHI 2012</li>


                <li>Seongkook Heo, Geehyuk Lee<br>
                <strong>Force Gesture: Augmented touch screen gestures using normal and tangential force</strong><br>
                UIST 2011</li>


                <li>Seongkook Heo, Jaehyun Han, Sangwon Choi, Seunghwan Lee, Geehyuk Lee, Hyong-Euk Lee, SangHyun Kim,
                Won-Chul Bang, DoKyoon Kim, and ChangYeong Kim<br>
                <strong>IrCube Tracker: An Optical 6-DOF Tracker based on LED Directivity</strong><br>
                UIST 2011</li>


                <li>Seongkook Heo, Geehyuk Lee<br>
                <strong>ForceTap: Extending input vocabulary of mobile touch screen by adding tap gestures</strong><br>
                MobileHCI 2011</li>
            </ul>


            <h3 id="peer-reviewedjournalpapers">Peer-reviewed Journal Papers</h3>


            <ul>
                <li>Jaehyun Han, Seongkook Heo, Hyong-Euk Lee, and Geehyuk Lee<br>
                <strong>IrPen: A 6-DOF Pen System to Support Over-the-surface Interactions with Tablet
                Computers.</strong><br>
                IEEE Computer Graphics and Applications, 34(3)</li>


                <li>Jaehyun Han, Sangwon Choi, Seongkook Heo, and Geehyuk Lee.<br>
                <strong>Optical touch sensing based on internal scattering in a touch surface.</strong><br>
                Electronics Letters, 48(22):1420-1422, 2012</li>


                <li>Jaehyun Han, Seongkook Heo, Geehyuk Lee, Won-Chul Bang, DoKyoon Kim, and ChangYeong Kim.<br>
                <strong>6-DOF tracker using LED directivity.</strong><br>
                Electronics Letters, 47(3):177-178, 2011</li>
            </ul>


            <h3 id="bookchapters">Book Chapters</h3>


            <ul>
                <li>Seongkook Heo, Jaehyun Han, and Geehyuk Lee<br>
                <strong>Designing for Hover- and Force-Enriched Touch Interaction</strong><br>
                Computer-Human Interaction. Cognitive Effects of Spatial Interaction, Learning, and Ability Lecture
                Notes in Computer Science Volume 8433</li>
            </ul>


            <h3 id="postersanddemos">Posters and Demos</h3>


            <ul>
                <li>To be updated</li>
            </ul>


            <h3 id="patents">Patents</h3>

            <ul>
                <li>To be updated</li>
            </ul>
        </div>
    </section>


    <section class="content-section" id="fun">
        <div class="container">
            <h2>Side Projects</h2>            
            I have done several side projects with lab mates and friends, which were fun and also rewarding(!). 

            <h4 class="project-title">Grip-to-identify</h4>
            <p class="project-content">
            Using a touch-sensitive mouse, we built a system that measures your mouse grip and identifies who you are. We got a 2nd place People's choice award at UIST '11 Student Innovation Contest. <a href="https://www.youtube.com/watch?v=83hrdlR8Vlo">Video</a>
            </p>

            <h4 class="project-title">TteokPad: Slingshot</h4>
            <p class="project-content">
            We built a slingshot device that is controlled with a force-sensitive touchpad. We named it as TteokPad, where 'Tteok' is how we call rice cakes in Korean. We received 2nd place People's choice award again at UIST '12 Student Innovation Contest. <a href="https://www.youtube.com/watch?v=Hk52ixuC_M0">Video</a>
            </p>
            
            <h4 class="project-title">Waterpump bagpipe</h4>
            <p class="project-content">
            In this project, we bulit a system that controls the water level in a glass bottle and lets users to blow wind by pressing an air bag. This project got into the 2nd Place in Most Creative section at UIST '13 Student Innovation Contest. <a href="https://www.youtube.com/watch?v=8pY_USsqFxs">Video</a>
            </p>

            <h2>Bike and me</h2>
            I love bikes. Here are some pictures of my bikes and myself. 


        </div>
    </section>


    <div class="container">
        Last update: Feb 20, 2016
    </div>
    <script src="js/jquery.js">
    </script> 
    <script src="js/jquery.easing.min.js">
    </script> 
    <script src="js/scrolling-nav.js">
    </script> 
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-42369249-2', 'auto');
      ga('send', 'pageview');
    </script>
</body>
</html>