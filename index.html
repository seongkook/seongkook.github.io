<!DOCTYPE html>

<html lang="en">
<head>
    <meta charset="utf-8">
    <meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible">
    <meta content="width=device-width, initial-scale=1.0" name="viewport">
    <meta content="" name="description">
    <meta content="" name="author">

    <title>Seongkook Heo</title>
    <link crossorigin="anonymous" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css"
    integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" rel="stylesheet">
    <link href="mystyle.css" rel="stylesheet" type="text/css"><!-- Optional theme -->
    <link crossorigin="anonymous" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap-theme.min.css"
    integrity="sha384-fLW2N01lMqjakBkx3l/M9EahuwpSfeNvV63J5ezn3uZzapT0u7EYsXMjQV+0En5r" rel="stylesheet">
    <!-- Latest compiled and minified JavaScript -->

    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js">
    </script>
</head>

<body data-spy="scroll" data-target=".navbar-fixed-top" id="page-top">
    <nav class="navbar navbar-default navbar-fixed-top" role="navigation">
        <div class="container">
            <div class="navbar-header page-scroll">
                <button class="navbar-toggle" data-target=".navbar-ex1-collapse" data-toggle="collapse" type=
                "button"><span class="sr-only">Toggle navigation</span> <span class="icon-bar"></span> <span class=
                "icon-bar"></span> <span class="icon-bar"></span></button> <a class="navbar-brand page-scroll" href=
                "#page-top"><strong>Seongkook Heo</strong></a>
            </div>
            <!-- Collect the nav links, forms, and other content for toggling -->


            <div class="collapse navbar-collapse navbar-ex1-collapse navbar-right">
                <ul class="nav navbar-nav">
                    <!-- Hidden li included to remove active class from about link when scrolled up past about section -->


                    <li class="hidden">
                        <a class="page-scroll" href="#page-top"></a>
                    </li>


                    <li>
                        <a class="page-scroll" href="#page-top">About</a>
                    </li>


                    <li>
                        <a class="page-scroll" href="#research">Research</a>
                    </li>


                    <li>
                        <a class="page-scroll" href="#publication">Publication</a>
                    </li>


                    <li>
                        <a class="page-scroll" href="#fun">Fun</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>


    <section class="intro-section" id="about">
        <div class="container"><img class="img-responsive" src="me.jpg">
        </div>


        <div class="container">
            <h1 id="seongkookheo">Seongkook Heo</h1>


            <p>Hi. I&#8217;m Seongkook Heo, a PhD candidate at the <a href="http://kaist.ac.kr">KAIST</a>. I&#8217;m
            studying HCI, especially things related to developing new way to interact with computers in different-form
            factors, with my advisor <a href="http://hcil.kaist.ac.kr/">Geehyuk Lee</a>. I was lucky to have chances to
            collaborate with different companies, such as Samsung Electronics, Hyundai Motors, Golfzon, and Hancom, and
            with researchers in different departments, from electronic engineering to industrial design. Last summer, I
            was an intern at Microsoft Research with Ken Hinckley, which was also a great experience. I learned a lot
            from these experiences. I'm currently at Autodesk Research in Toronto for my internship with Tovi
            Grossman.</p>


            <p>I always have been a geek and it is exciting to see the technologies that I&#8217;ve seen in books and
            movies are becoming real. Now computers are everywhere, and even very small computers like the ones on our
            wrist are strong enough to run various apps and connected to the internet. However, I think computers are
            still not paying enough attention to us, like what we wanted to do, what we can do, or what we really meant
            to do, so that we have to put much effort to let them work for us. I am enthusiastic about making these
            &#8216;rude&#8217; computers to become more sensitive to us, so that we can benefit the mighty power of
            computers better.</p>


            <p>What I love: thinking and building new idea, solving problems, things that are beautiful, either
            aesthetically, logically, or mecahnically, or something with a brilliant idea. I also love bikes. Since I
            was 19, I have been on a bike saddle except one or two years. I love the simple nature of the bike (which
            is becoming more complex these days, but still all parts visible), and solid mechanical link that converts
            my subtle musclular movement into the bike movement without any latency (please, no plastic cranks).</p>


            <p><a href="mailto:seongkook@kaist.ac.kr"><strong>Email</strong></a> | <a href=
            "cv.pdf"><strong>CV</strong></a> | <a href=
            "https://scholar.google.com/citations?hl=en&amp;user=7r0_F0kAAAAJ"><strong>Google scholar</strong></a></p>
        </div>
        <!--p.s: I'm on a job market. Please ping me if you're interested.-->
    </section>


    <section class="content-section" id="research">
        <div class="container">
            <h2 id="research">Research</h2>


            <p>Our natural touch is rich and nuanced with full of physical properties such as force and posture
            implying our intentions. Touch interfaces, however, ignore this rich information and only consider whether
            our finger is in contact within a screen area and the contact location. In this talk, I will present
            different approaches my colleagues and I made to enhance impoverished touch interaction, for instance by
            using additional modalities like force or hover, or by exploiting underutilized touch gestures.</p>


            <h3 id="force-enrichedtouch">Force-enriched touch</h3>


            <h4>Force Gestures</h4>


            <p>When we touch a real world object, physics counts. We automatically control force in multiple
            directions. It creates tremendous different manipulations and expresses different nuance. What if a touch
            screen can utilize multi-dimensional force with touch operation? In this project, we developed a normal-
            and tangential-force sensing mobile touch device and showed the potential of combining touch with force
            with application scenarios.</p>


            <p>Presented at UIST &#8217;11. <a href="">Paper</a> / <a href="">Video</a></p>


            <h4>ForceTap</h4>


            <p>Force is a great modality that can enrich touch with continuous pressure level. But as of 2011, there
            were almost no device with force-sensing capability except the BlackBerry Storm 2, which was unfortunately
            not very successful. It is understandable since adding force sensors would result in the increased
            manufacturing price and more complex structure. We came with a new idea of using an accelerometer, which
            almost all modern mobile devices have, to detect a strong and gentle tap by measuring the device movement
            made by a tap.</p>


            <p>Presented at MobileHCI &#8217;11. <a href="">Paper</a> / <a href="">Video</a></p>


            <h4>ForceDrag</h4>


            <p>We thought about using force for touch input modifier, like using modifier keys to make a mouse drag
            work for a different function. During the process, we found that the friction makes the forceful movement
            difficult to make (which is too obvious). So we proposed a new way, named &#8216;force lock&#8217; to
            support light drag after selecting a mode with a different force level. We also discussed pros and cons of
            using force lock compared to just using force as a modifier.</p>


            <p>Presented at OZCHI &#8217;12 <a href="">Paper</a> / <a href="">Video</a></p>


            <h4>Multi-touch Shear Interaction</h4>


            <p>Use of a tangential force has been introduced in 2011 as noted above. But think about how we interact
            with objects and also touch surfaces. We use multiple fingers.</p>


            <p>Presented at CHI &#8217;13. <a href="">Paper</a> / <a href="">Video</a></p>


            <h3 id="hover-enrichedtouch">Hover-enriched touch</h3>


            <h4>ThickPad</h4>


            <p>This work was presented as a demonstration at UIST. This special optical touchpad has an array of
            infrared LEDs and Photo Transistors and a touch-sensitive layer on it. Thus, it can measure hovering
            finger. Not only where it is, but also how it is tilted / shaped.</p>


            <p>Presented at UIST '11 (Demo) <a href="paper%20link">Paper</a> | <a href="paper%20link">Video</a></p>


            <h4>LongPad</h4>


            <p>We bulit a larger optical touchpad so that it can cover the whole palm rest area of a laptop.</p>


            <p>Presented at CHI '13 <a href="paper%20link">Paper</a> | <a href="paper%20link">Video</a></p>


            <h4>2.5D interaction</h4>


            <p>What if we can combine both hover and force? How should we design interaction for this rich input?</p>


            <p>Presented at OZCHI '13 <a href="paper%20link">Paper</a></p>


            <p>Book Chapter <a href="paper%20link">Paper</a></p>


            <h4>PreTouch</h4>


            <p>This work is from my internship with Ken Hinckley at MSR during 2015 summer. Details to be described
            later.</p>


            <p>To be presented at CHI '16</p>


            <h3 id="gettingthemostoutoftouch">Getting the most out of touch</h3>


            <h4>Ta-ta-tap</h4>


            <p>We have fingers, whice is good.</p>


            <p>Presented at CHI '14 <a href="paper%20link">Paper</a> | <a href="paper%20link">Video</a></p>


            <h4>SplitBoard</h4>


            <p>We now have very small touch screen on our wrist. Can we type well?</p>


            <p>Presented at CHI '15 <a href="paper%20link">Paper</a> | <a href="paper%20link">Video</a></p>


            <h3 id="sensing6dof">Sensing 6DOF</h3>


            <h4>IrCube</h4>


            <p>IrCube is an optical 6-DOF tracker where a few photo-sensors can track the position and orientation of
            an LED cluster. The operating principle of the tracker is basically source localization by solving an
            inverse problem.</p>


            <p>Presented at UIST '11 <a href="paper%20link">Paper</a> | <a href="paper%20link">Video</a></p>


            <h4>IrPen</h4>


            <p>IrCube is an optical 6-DOF tracker where a few photo-sensors can track the position and orientation of
            an LED cluster. The operating principle of the tracker is basically source localization by solving an
            inverse problem.</p>


            <p>Published at CG&amp;A <a href="paper%20link">Paper</a> | <a href="paper%20link">Video</a></p>


            <h3 id="others">Understanding people</h3>


            <h4>Snapping</h4>


            <p>Results from previous research, we assumed using the centroid, rather than the bounding box center,
            would provide a better way to help users with aligning objects. Through a user study, we examined the
            position of a center perceived by a user when aligning objects.</p>


            <p>Presented at CHI '12 (WIP) <a href="paper%20link">Paper</a></p>


            <h4>Mining social relationship</h4>


            <p>Our goal is to show that it is possible to automatically infer social relationship types among people
            who stay together in an organization by analyzing communication patterns. We collected indoor co-location
            data and instant messenger data from 22 participants for one month. Based on the data, we designed and
            explored several indicators which are considered to be useful for mining social relationship types. We
            applied machine learning techniques using the indicators and found that it is possible to develop an
            intelligent method to infer social relationship types.</p>


            <p>Presented at CSCW '13 <a href="paper%20link">Paper</a></p>


            <h4>Participatory design</h4>


            <p>Yes, we need to design interactive systems in-situ.</p>


            <p>Presented at HCI Korea 2016 (Received best paper award) <a href="paper%20link">Paper</a> | <a href=
            "paper%20link">Video</a></p>
        </div>
    </section>


    <section class="content2-section" id="publication">
        <div class="container">
            <h2 id="publications">Publications</h2>


            <h3 id="peer-reviewedconerencepapersandnotes">Peer-reviewed Conerence Papers and Notes</h3>


            <ul>
                <li>Ken Hinckley, Seongkook Heo, Michel Pahud, Christian Holz, Hrvoje Benko, Abigail Sellen, Richard
                Banks, Kenton O’Hara, Gavin Smyth, and William Buxton<br>
                <strong>Pre-Touch Sensing for Mobile Interaction</strong><br>
                CHI2016 (to appear)</li>


                <li>Jonggi Hong, Seongkook Heo, Poika Isokoski, and Geehyuk Lee<br>
                <strong>SplitBoard: A Simple Split Soft Keyboard for Wristwatch-sized Touch Screens</strong><br>
                CHI 2015</li>


                <li>Seongkook Heo, Jiseong Gu, Geehyuk Lee<br>
                <strong>Expanding Touch Input Vocabulary by Using Consecutive Distant Taps</strong><br>
                CHI 2014</li>


                <li>Seongkook Heo, Jaehyun Han, Geehyuk Lee,<br>
                <strong>Designing Rich Touch Interaction through Proximity and 2.5D Force Sensing Touchpad</strong><br>
                OZCHI 2013</li>


                <li>Seongkook Heo, Geehyuk Lee<br>
                <strong>Indirect Shear Force Estimation for Multi-Point Shear Force Operations</strong><br>
                CHI 2013</li>


                <li>Jiseong Gu, SeongKook Heo, Jaehyun Han, Sunjun Kim, Geehyuk Lee<br>
                <strong>LongPad: A TouchPad Using the Entire Area below the Keyboard of a Laptop Computer</strong><br>
                CHI 2013</li>


                <li>Jinhyuk Choi, SeongKook Heo, Jaehyun Han, Geehyuk Lee, and Junehwa Song<br>
                <strong>Mining Social Relationship Types in an Organization using Communication Patterns</strong><br>
                CSCW 2013</li>


                <li>SeongKook Heo and Geehyuk Lee<br>
                <strong>ForceDrag: Using Pressure as a Touch Input Modifer</strong><br>
                OZCHI 2012</li>


                <li>Seongkook Heo, Geehyuk Lee<br>
                <strong>Force Gesture: Augmented touch screen gestures using normal and tangential force</strong><br>
                UIST 2011</li>


                <li>Seongkook Heo, Jaehyun Han, Sangwon Choi, Seunghwan Lee, Geehyuk Lee, Hyong-Euk Lee, SangHyun Kim,
                Won-Chul Bang, DoKyoon Kim, and ChangYeong Kim<br>
                <strong>IrCube Tracker: An Optical 6-DOF Tracker based on LED Directivity</strong><br>
                UIST 2011</li>


                <li>Seongkook Heo, Geehyuk Lee<br>
                <strong>ForceTap: Extending input vocabulary of mobile touch screen by adding tap gestures</strong><br>
                MobileHCI 2011</li>
            </ul>


            <h3 id="peer-reviewedjournalpapers">Peer-reviewed Journal Papers</h3>


            <ul>
                <li>Jaehyun Han, Seongkook Heo, Hyong-Euk Lee, and Geehyuk Lee<br>
                <strong>IrPen: A 6-DOF Pen System to Support Over-the-surface Interactions with Tablet
                Computers.</strong><br>
                IEEE Computer Graphics and Applications, 34(3)</li>


                <li>Jaehyun Han, Sangwon Choi, Seongkook Heo, and Geehyuk Lee.<br>
                <strong>Optical touch sensing based on internal scattering in a touch surface.</strong><br>
                Electronics Letters, 48(22):1420-1422, 2012</li>


                <li>Jaehyun Han, Seongkook Heo, Geehyuk Lee, Won-Chul Bang, DoKyoon Kim, and ChangYeong Kim.<br>
                <strong>6-DOF tracker using LED directivity.</strong><br>
                Electronics Letters, 47(3):177-178, 2011</li>
            </ul>


            <h3 id="bookchapters">Book Chapters</h3>


            <ul>
                <li>Seongkook Heo, Jaehyun Han, and Geehyuk Lee<br>
                <strong>Designing for Hover- and Force-Enriched Touch Interaction</strong><br>
                Computer-Human Interaction. Cognitive Effects of Spatial Interaction, Learning, and Ability Lecture
                Notes in Computer Science Volume 8433</li>
            </ul>


            <h3 id="postersanddemos">Posters and Demos</h3>
            <ul>
                <li>To be updated</li>
            </ul>
            
            <h3 id="patents">Patents</h3>
            <ul>
                <li>To be updated</li>
            </ul>
        </div>
    </section>


    <section class="content-section" id="fun">
        <div class="container">
            <h2>Bike and me</h2>
            I love bike.
        </div>
    </section>


    <div class="container">
        Last update: Feb 20, 2016
    </div>
    <script src="jquery.js">
    </script> 
    <script src="jquery.easing.min.js">
    </script> 
    <script src="scrolling-nav.js">
    </script>
</body>
</html>